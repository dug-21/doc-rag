# Prometheus Alert Rules for Doc-RAG Production
# Comprehensive alerting for security, performance, and reliability

groups:
  - name: doc-rag-critical
    interval: 30s
    rules:
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "Service {{ $labels.job }} has been down for more than 1 minute"
          runbook_url: "https://docs.docrag.com/runbook/service-down"

      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
          team: application
        annotations:
          summary: "High error rate on {{ $labels.job }}"
          description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.job }}"
          runbook_url: "https://docs.docrag.com/runbook/high-error-rate"

      - alert: DatabaseConnectionFailure
        expr: postgres_up == 0
        for: 1m
        labels:
          severity: critical
          team: database
        annotations:
          summary: "PostgreSQL database is unreachable"
          description: "Cannot connect to PostgreSQL database for more than 1 minute"
          runbook_url: "https://docs.docrag.com/runbook/database-connection"

      - alert: RedisConnectionFailure
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
          team: cache
        annotations:
          summary: "Redis cache is unreachable"
          description: "Cannot connect to Redis cache for more than 1 minute"
          runbook_url: "https://docs.docrag.com/runbook/redis-connection"

  - name: doc-rag-security
    interval: 30s
    rules:
      - alert: SuspiciousTraffic
        expr: rate(http_requests_total{status="429"}[5m]) > 10
        for: 2m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "High rate of blocked requests detected"
          description: "Rate limiting is blocking {{ $value }} requests per second"
          runbook_url: "https://docs.docrag.com/runbook/suspicious-traffic"

      - alert: AuthenticationFailures
        expr: rate(auth_failures_total[5m]) > 5
        for: 2m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "High authentication failure rate"
          description: "{{ $value }} authentication failures per second over the last 5 minutes"
          runbook_url: "https://docs.docrag.com/runbook/auth-failures"

      - alert: SecurityViolation
        expr: rate(security_violations_total[5m]) > 1
        for: 1m
        labels:
          severity: critical
          team: security
        annotations:
          summary: "Security policy violations detected"
          description: "{{ $value }} security violations per second detected"
          runbook_url: "https://docs.docrag.com/runbook/security-violation"

      - alert: UnauthorizedAccess
        expr: rate(http_requests_total{status="401"}[5m]) > 5
        for: 3m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "High rate of unauthorized access attempts"
          description: "{{ $value }} unauthorized access attempts per second"
          runbook_url: "https://docs.docrag.com/runbook/unauthorized-access"

  - name: doc-rag-performance
    interval: 60s
    rules:
      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
          team: application
        annotations:
          summary: "High latency on {{ $labels.job }}"
          description: "95th percentile latency is {{ $value | humanizeDuration }} for {{ $labels.job }}"
          runbook_url: "https://docs.docrag.com/runbook/high-latency"

      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value | humanizePercentage }} on {{ $labels.instance }}"
          runbook_url: "https://docs.docrag.com/runbook/high-memory"

      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value | humanizePercentage }} on {{ $labels.instance }}"
          runbook_url: "https://docs.docrag.com/runbook/high-cpu"

      - alert: DiskSpaceLow
        expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 85
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Disk usage is {{ $value | humanizePercentage }} on {{ $labels.instance }} ({{ $labels.mountpoint }})"
          runbook_url: "https://docs.docrag.com/runbook/low-disk-space"

  - name: doc-rag-application
    interval: 60s
    rules:
      - alert: QueryProcessingErrors
        expr: rate(query_processing_errors_total[5m]) > 0.1
        for: 3m
        labels:
          severity: warning
          team: application
        annotations:
          summary: "High query processing error rate"
          description: "Query processing errors: {{ $value }} per second"
          runbook_url: "https://docs.docrag.com/runbook/query-errors"

      - alert: EmbeddingServiceDown
        expr: embedding_service_healthy != 1
        for: 2m
        labels:
          severity: critical
          team: ml
        annotations:
          summary: "Embedding service is unhealthy"
          description: "Embedding service health check failing for more than 2 minutes"
          runbook_url: "https://docs.docrag.com/runbook/embedding-service"

      - alert: VectorSearchLatency
        expr: histogram_quantile(0.95, rate(vector_search_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
          team: search
        annotations:
          summary: "Vector search latency is high"
          description: "95th percentile vector search latency: {{ $value | humanizeDuration }}"
          runbook_url: "https://docs.docrag.com/runbook/vector-search-latency"

      - alert: ChunkingQueueBacklog
        expr: chunking_queue_size > 1000
        for: 10m
        labels:
          severity: warning
          team: processing
        annotations:
          summary: "Large backlog in chunking queue"
          description: "Chunking queue has {{ $value }} items pending"
          runbook_url: "https://docs.docrag.com/runbook/chunking-backlog"

  - name: doc-rag-data
    interval: 60s
    rules:
      - alert: DatabaseConnectionsHigh
        expr: pg_stat_activity_count / pg_settings_max_connections * 100 > 80
        for: 5m
        labels:
          severity: warning
          team: database
        annotations:
          summary: "High database connection usage"
          description: "Database connections at {{ $value | humanizePercentage }} of maximum"
          runbook_url: "https://docs.docrag.com/runbook/db-connections"

      - alert: DatabaseSlowQueries
        expr: rate(pg_stat_statements_mean_time[5m]) > 1000
        for: 5m
        labels:
          severity: warning
          team: database
        annotations:
          summary: "Slow database queries detected"
          description: "Average query time: {{ $value }} milliseconds"
          runbook_url: "https://docs.docrag.com/runbook/slow-queries"

      - alert: VectorDatabaseDiskUsage
        expr: qdrant_disk_usage_percent > 85
        for: 5m
        labels:
          severity: warning
          team: storage
        annotations:
          summary: "Vector database disk usage high"
          description: "Qdrant disk usage: {{ $value | humanizePercentage }}"
          runbook_url: "https://docs.docrag.com/runbook/vector-db-storage"

      - alert: RedisMemoryHigh
        expr: redis_memory_used_bytes / redis_config_maxmemory * 100 > 90
        for: 5m
        labels:
          severity: critical
          team: cache
        annotations:
          summary: "Redis memory usage critical"
          description: "Redis memory usage: {{ $value | humanizePercentage }}"
          runbook_url: "https://docs.docrag.com/runbook/redis-memory"

  - name: doc-rag-business
    interval: 300s  # 5 minutes
    rules:
      - alert: LowQueryAccuracy
        expr: avg_over_time(query_accuracy_score[1h]) < 0.9
        for: 15m
        labels:
          severity: warning
          team: ml
        annotations:
          summary: "Query accuracy below threshold"
          description: "Average query accuracy: {{ $value | humanizePercentage }} (target: 90%+)"
          runbook_url: "https://docs.docrag.com/runbook/query-accuracy"

      - alert: DocumentIngestionStalled
        expr: rate(documents_ingested_total[30m]) == 0
        for: 1h
        labels:
          severity: warning
          team: ingestion
        annotations:
          summary: "Document ingestion has stalled"
          description: "No documents ingested in the last hour"
          runbook_url: "https://docs.docrag.com/runbook/ingestion-stalled"

      - alert: EmbeddingModelPerformance
        expr: histogram_quantile(0.95, rate(embedding_generation_duration_seconds_bucket[30m])) > 5
        for: 15m
        labels:
          severity: warning
          team: ml
        annotations:
          summary: "Embedding generation performance degraded"
          description: "95th percentile embedding generation time: {{ $value | humanizeDuration }}"
          runbook_url: "https://docs.docrag.com/runbook/embedding-performance"

  - name: doc-rag-monitoring
    interval: 60s
    rules:
      - alert: PrometheusTargetDown
        expr: up{job="prometheus"} == 0
        for: 5m
        labels:
          severity: critical
          team: monitoring
        annotations:
          summary: "Prometheus monitoring is down"
          description: "Prometheus has been down for more than 5 minutes"

      - alert: AlertManagerDown
        expr: up{job="alertmanager"} == 0
        for: 5m
        labels:
          severity: critical
          team: monitoring
        annotations:
          summary: "AlertManager is down"
          description: "AlertManager has been down for more than 5 minutes"

      - alert: TooManyAlerts
        expr: count by(instance, job) (ALERTS{alertstate="firing"}) > 10
        for: 5m
        labels:
          severity: warning
          team: monitoring
        annotations:
          summary: "Too many active alerts"
          description: "{{ $value }} alerts are currently firing"